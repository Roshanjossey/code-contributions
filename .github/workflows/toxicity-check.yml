name: Check for Toxic Content

on:
  pull_request:
    paths:
      - "**.html"  

jobs:
  moderate-content:
    runs-on: ubuntu-latest  

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3  

      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: "3.x"  

      - name: Cache Hugging Face models
        uses: actions/cache@v3
        with:
          path: ~/.cache/huggingface  
          key: huggingface-toxicity-model

      - name: Install dependencies
        run: pip install transformers torch  

      - name: Run toxicity check
        run: python scripts/check_toxicity.py

      - name: Auto-approve PR if no offensive content is found
        if: success()
        uses: hmarr/auto-approve-action@v3
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Comment on PR if offensive content is detected
        if: failure()
        uses: thollander/actions-comment-pull-request@v2
        with:
          message: "ðŸš¨ Offensive content detected. Please review your PR."
